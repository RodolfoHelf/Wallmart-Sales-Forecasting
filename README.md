# ğŸª Walmart Sales Forecasting Project

A comprehensive machine learning project for forecasting Walmart sales using advanced data processing, feature engineering, and multiple ML models.

## ğŸ“ **Clean & Organized Project Structure**

```
Wallmart-Sales-Forecasting/
â”œâ”€â”€ ğŸ“ app/                    # FastAPI web application
â”‚   â”œâ”€â”€ main.py               # Main API endpoints
â”‚   â”œâ”€â”€ config.py             # Configuration settings
â”‚   â”œâ”€â”€ database.py           # Database connections
â”‚   â””â”€â”€ models/               # Database models & schemas
â”‚
â”œâ”€â”€ ğŸ“ data/                  # Data processing modules
â”‚   â”œâ”€â”€ data_processor.py     # CSV loading & cleaning
â”‚   â”œâ”€â”€ feature_engineering.py # Feature creation (111+ features)
â”‚   â””â”€â”€ Walmart.csv           # Raw input data
â”‚
â”œâ”€â”€ ğŸ“ models/                # ML model training
â”‚   â”œâ”€â”€ train_models.py       # Full MLflow training
â”‚   â””â”€â”€ quick_test.py         # Fast validation testing
â”‚
â”œâ”€â”€ ğŸ“ scripts/               # Execution scripts
â”‚   â”œâ”€â”€ ğŸ“ pipeline/          # Full pipeline execution
â”‚   â”‚   â”œâ”€â”€ run_full_pipeline.py
â”‚   â”‚   â”œâ”€â”€ run_pipeline.bat
â”‚   â”‚   â”œâ”€â”€ run_pipeline.ps1
â”‚   â”‚   â””â”€â”€ pipeline_requirements.txt
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ quick_test/        # Quick model testing
â”‚       â”œâ”€â”€ run_quick_test.bat
â”‚       â””â”€â”€ run_quick_test.ps1
â”‚
â”œâ”€â”€ ğŸ“ docs/                  # Documentation
â”‚   â”œâ”€â”€ README.md             # This file
â”‚   â”œâ”€â”€ STARTUP_GUIDE.md      # Setup & deployment guide
â”‚   â”œâ”€â”€ ğŸ“ pipeline/          # Pipeline documentation
â”‚   â”‚   â””â”€â”€ PIPELINE_README.md
â”‚   â””â”€â”€ ğŸ“ quick_test/        # Quick test documentation
â”‚       â””â”€â”€ QUICK_TEST_README.md
â”‚
â”œâ”€â”€ ğŸ“ config/                # Configuration files
â”‚   â”œâ”€â”€ docker-compose.yml    # Docker services
â”‚   â”œâ”€â”€ env.example           # Environment variables template
â”‚   â”œâ”€â”€ init.sql              # Database initialization
â”‚   â”œâ”€â”€ requirements.txt      # Main dependencies
â”‚   â””â”€â”€ setup.py              # Package setup
â”‚
â”œâ”€â”€ ğŸ“ outputs/               # Generated outputs
â”‚   â”œâ”€â”€ pipeline_outputs/     # Full pipeline results
â”‚   â”‚   â”œâ”€â”€ processed_data.csv
â”‚   â”‚   â”œâ”€â”€ featured_data.csv
â”‚   â”‚   â”œâ”€â”€ trained_models/
â”‚   â”‚   â””â”€â”€ pipeline_summary.json
â”‚   â””â”€â”€ pipeline.log          # Execution logs
â”‚
â”œâ”€â”€ ğŸ“ eda/                   # Exploratory Data Analysis
â”‚   â””â”€â”€ [EDA files...]
â”‚
â”œâ”€â”€ ğŸ“ mlflow/                # MLflow experiment tracking
â”œâ”€â”€ ğŸ“ tests/                 # Test files
â””â”€â”€ run.py                    # Main application runner
```

## ğŸš€ **Quick Start Guide**

### **1. Full Pipeline Execution** (Recommended)
```bash
# Navigate to pipeline scripts
cd scripts/pipeline

# Run the complete pipeline
python run_full_pipeline.py
# OR
run_pipeline.bat          # Windows
# OR
.\run_pipeline.ps1        # PowerShell
```

### **2. Quick Model Testing**
```bash
# Navigate to quick test scripts
cd scripts/quick_test

# Run quick validation
python ../models/quick_test.py
# OR
run_quick_test.bat        # Windows
# OR
.\run_quick_test.ps1      # PowerShell
```

### **3. Start Web Dashboard**
```bash
# From project root
python run.py
```

## ğŸ“Š **What the Pipeline Does**

1. **ğŸ“ Data Processing**: Loads `Walmart.csv` â†’ Cleans & validates â†’ Saves to `outputs/processed_data.csv`
2. **ğŸ”§ Feature Engineering**: Creates 111+ features â†’ Saves to `outputs/featured_data.csv`
3. **ğŸ¤– Model Training**: Trains 4 model types for 5 stores â†’ Saves to `outputs/trained_models/`

## ğŸ¯ **Key Features**

- âœ… **Clean Organization**: Logical folder structure
- âœ… **Fast Execution**: Pipeline completes in ~1 second
- âœ… **Rich Features**: 111+ engineered features
- âœ… **Multiple Models**: Trend, Seasonal, Moving Average, Feature-based
- âœ… **Easy Execution**: Batch files & PowerShell scripts
- âœ… **Comprehensive Outputs**: CSV files, JSON summaries, logs

## ğŸ“š **Documentation**

- **ğŸ“– Main Guide**: `docs/README.md` (this file)
- **ğŸš€ Pipeline Guide**: `docs/pipeline/PIPELINE_README.md`
- **âš¡ Quick Test Guide**: `docs/quick_test/QUICK_TEST_README.md`
- **âš™ï¸ Setup Guide**: `docs/STARTUP_GUIDE.md`

## ğŸ”§ **Requirements**

```bash
# Install main dependencies
pip install -r config/requirements.txt

# Install pipeline dependencies
pip install -r scripts/pipeline/pipeline_requirements.txt
```

## ğŸ“ **Output Files**

After running the pipeline, check `outputs/pipeline_outputs/`:
- `processed_data.csv` - Cleaned data (16 columns)
- `featured_data.csv` - Enhanced data (127 columns)
- `trained_models/` - Model results & artifacts
- `pipeline_summary.json` - Complete execution summary

## ğŸ‰ **Benefits of New Structure**

- **ğŸ§¹ Clean Root**: Only essential files in main directory
- **ğŸ“ Logical Grouping**: Scripts, docs, configs organized by purpose
- **ğŸ” Easy Navigation**: Find what you need quickly
- **ğŸ“š Clear Documentation**: Each component has its own docs folder
- **âš¡ Fast Execution**: Scripts are in dedicated folders with clear paths

---

**ğŸ¯ Ready to use! Start with the pipeline scripts in `scripts/pipeline/` for the full experience, or use quick test in `scripts/quick_test/` for fast validation.**
