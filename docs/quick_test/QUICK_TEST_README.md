# üöÄ Quick Model Test - Fast Execution Version

## Overview
The Quick Model Test is a lightweight, fast-executing version of the Walmart sales forecasting model training pipeline. It's designed for rapid testing and validation without the overhead of full ML libraries or database connections.

## ‚ö° Performance
- **Total Execution Time**: ~0.01-0.03 seconds
- **Data Size**: 100 synthetic samples (configurable)
- **Models Tested**: 3 (SARIMAX, LightGBM, Ensemble)
- **Dependencies**: Minimal (only pandas + numpy)

## üéØ Use Cases
- **Quick Validation**: Test model logic before full training
- **Development**: Iterate on model approaches rapidly
- **CI/CD**: Fast model validation in automated pipelines
- **Demo**: Show model capabilities without waiting
- **Testing**: Validate model components independently

## üì¶ Requirements
```bash
# Install minimal dependencies
pip install -r quick_test_requirements.txt
```

**Dependencies:**
- `pandas>=1.3.0` - Data manipulation
- `numpy>=1.21.0` - Numerical computations

## üöÄ Running the Test

### Method 1: Direct Python Execution
```bash
python models/quick_test.py
```

### Method 2: Windows Batch File
```bash
run_quick_test.bat
```

### Method 3: PowerShell Script
```powershell
.\run_quick_test.ps1
```

## üìä What Gets Tested

### 1. **Quick SARIMAX Test**
- Trend analysis using polynomial fitting
- Seasonality detection (4-week cycles)
- Basic forecasting (next 4 weeks)
- MAPE calculation
- **Execution Time**: ~0.001s

### 2. **Quick LightGBM Test**
- Feature engineering (time-based features)
- Lag variables (1-week, 4-week)
- Rolling statistics (4-week mean)
- Feature importance (correlation analysis)
- **Execution Time**: ~0.005s

### 3. **Quick Ensemble Test**
- Combines SARIMAX and LightGBM results
- Average forecasting approach
- Ensemble MAPE calculation
- **Execution Time**: ~0.003s

## üîç Test Output

### Console Output
```
üè™ Walmart Sales Forecasting - Quick Model Test
==================================================

üìä Test Results Summary:
------------------------------
‚úÖ Status: Success
‚è±Ô∏è  Total Time: 0.011s
üìä Models Tested: 3
‚úÖ Successful: 3

üìà Data Summary:
   ‚Ä¢ Samples: 100
   ‚Ä¢ Date Range: 2023-01-01 to 2024-11-24
   ‚Ä¢ Mean Sales: $56,096
   ‚Ä¢ Sales Std: $8,758

üîç Individual Model Results:
   ‚Ä¢ SARIMAX: 0.000s, MAPE: 13.29%
   ‚Ä¢ LIGHTGBM: 0.005s, MAPE: 13.53%
   ‚Ä¢ ENSEMBLE: 0.003s, MAPE: N/A
```

### Log Output
- Detailed execution logs with timestamps
- Performance metrics for each model
- Error handling and status reporting

## ‚öôÔ∏è Configuration

### Data Size
```python
# In quick_test.py, modify the n_samples parameter
results = tester.run_quick_test_suite(n_samples=100)  # Default: 100
```

### Model Selection
```python
# The test suite automatically runs all 3 models
# To test individual models, call them directly:
sarimax_result = tester.quick_sarimax_test(test_data)
lightgbm_result = tester.quick_lightgbm_test(test_data)
ensemble_result = tester.quick_ensemble_test(test_data)
```

## üîß Customization

### Adding New Models
```python
def quick_new_model_test(self, data: pd.DataFrame) -> Dict[str, Any]:
    """Add your custom quick model test here"""
    start_time = time.time()
    
    try:
        # Your model logic here
        # ...
        
        return {
            'model_name': 'quick_new_model',
            'execution_time': time.time() - start_time,
            'status': 'success',
            # ... other metrics
        }
    except Exception as e:
        return {
            'model_name': 'quick_new_model',
            'execution_time': time.time() - start_time,
            'error': str(e),
            'status': 'failed'
        }
```

### Modifying Test Data
```python
def generate_test_data(self, n_samples: int = 100) -> pd.DataFrame:
    """Customize synthetic data generation"""
    # Modify the data generation logic here
    # Add new features, change patterns, etc.
```

## üìà Performance Benchmarks

| Model | Execution Time | Data Points | Features |
|-------|----------------|-------------|----------|
| SARIMAX | ~0.001s | 100 | 6 |
| LightGBM | ~0.005s | 100 | 9 |
| Ensemble | ~0.003s | 100 | Combined |
| **Total** | **~0.01s** | **100** | **All** |

## üö® Limitations

### What's Simplified
- **No ML Libraries**: Uses simplified implementations instead of full MLflow, LightGBM, etc.
- **Synthetic Data**: Generates test data instead of loading from database
- **Basic Metrics**: Simplified MAPE and forecasting calculations
- **No Persistence**: Results are not saved to MLflow or database

### What's Not Tested
- **Database Integration**: No real data loading
- **MLflow Tracking**: No experiment logging
- **Full Model Training**: Simplified algorithms only
- **Production Features**: No deployment or scaling

## üîÑ Integration with Full Pipeline

### Before Full Training
```bash
# 1. Run quick test for validation
python models/quick_test.py

# 2. If successful, run full training
python models/train_models.py
```

### In CI/CD Pipeline
```yaml
# Example GitHub Actions step
- name: Quick Model Test
  run: |
    pip install -r models/quick_test_requirements.txt
    python models/quick_test.py
```

## üêõ Troubleshooting

### Common Issues
1. **Import Errors**: Ensure you're in the correct directory
2. **Dependency Issues**: Install requirements with `pip install -r quick_test_requirements.txt`
3. **Performance**: Test runs should complete in <0.1 seconds

### Debug Mode
```python
# Add debug logging
logging.basicConfig(level=logging.DEBUG)
```

## üìö Next Steps

After successful quick testing:
1. **Validate Results**: Check that MAPE and forecasts make sense
2. **Full Training**: Run `python models/train_models.py` for complete training
3. **Database Setup**: Ensure PostgreSQL and MLflow are running
4. **Production Deployment**: Deploy validated models to production

---

**Happy Quick Testing! üöÄ‚ö°**
